{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIYdn1woOS1n",
    "outputId": "d6a3872e-734e-4674-b8a0-0290d85d98f5"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    losses,\n",
    "    metrics,\n",
    "    datasets,\n",
    "    mixed_precision,\n",
    "    optimizers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    \"dataset_name\": \"CIFAR-10\",\n",
    "    \"image_size\": 32,\n",
    "    \"target_size\": 72,\n",
    "    \"patch_size\": 9,\n",
    "    \"num_mixer_layers\": 4,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"channels_mlp_dim\": 128,\n",
    "    \"num_classes\": 10,\n",
    "    \"dropout\": 0.25,\n",
    "    \"batch_size\": 512,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 50,\n",
    "    \"label_smoothing\": 0.0,\n",
    "    \"mixed_precision\": False,\n",
    "    \"class_names\": [\n",
    "        \"airplane\", \"automobile\", \"bird\", \"cat\",\n",
    "        \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIGS[\"mixed_precision\"]:\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lbRgIu0BbTF"
   },
   "outputs": [],
   "source": [
    "def get_cifar10(num_classes: int):\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_cifar10(num_classes=10)\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"x_test.shape:\", x_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6qEXvcVR7ZJ"
   },
   "outputs": [],
   "source": [
    "def get_preprocessing_layer(\n",
    "    data_batch: Union[np.ndarray, tf.Tensor], target_size: int\n",
    ") -> Sequential:\n",
    "    normalization = preprocessing.Normalization()\n",
    "    normalization.adapt(data_batch)\n",
    "    resize = preprocessing.Resizing(target_size, target_size)\n",
    "    return Sequential([normalization, resize], name=\"preprocessing\")\n",
    "\n",
    "\n",
    "def get_augmentation_layer() -> Sequential:\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            preprocessing.RandomFlip(\"horizontal\"),\n",
    "            preprocessing.RandomRotation(factor=0.02),\n",
    "            preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        ],\n",
    "        name=\"augmentation\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_8cOi71NDCPC"
   },
   "outputs": [],
   "source": [
    "def patch_embedding(\n",
    "    inputs: tf.Tensor, embedding_dim: int, patch_size: int\n",
    ") -> tf.Tensor:\n",
    "    x = layers.Conv2D(embedding_dim, kernel_size=patch_size, strides=patch_size)(inputs)\n",
    "    return layers.Reshape((x.shape[1] * x.shape[2], x.shape[3]))(x)\n",
    "\n",
    "\n",
    "def mlp_block(inputs: tf.Tensor, mlp_dim: int) -> tf.Tensor:\n",
    "    x = layers.Dense(mlp_dim)(inputs)\n",
    "    x = layers.Activation(\"gelu\")(x)\n",
    "    return layers.Dense(x.shape[-1])(x)\n",
    "\n",
    "\n",
    "def mixer_block(inputs: tf.Tensor, tokens_mlp_dim, channels_mlp_dim) -> tf.Tensor:\n",
    "    y = layers.LayerNormalization()(inputs)\n",
    "    y = layers.Permute((2, 1))(y)\n",
    "    # Token Mixing\n",
    "    y = mlp_block(y, tokens_mlp_dim)\n",
    "    y = layers.Permute((2, 1))(y)\n",
    "    x = layers.Add()([inputs, y])\n",
    "    # Channel Mixing\n",
    "    y = layers.LayerNormalization()(x)\n",
    "    y = mlp_block(y, channels_mlp_dim)\n",
    "    return layers.Add()([x, y])\n",
    "\n",
    "\n",
    "def get_mlp_mixer_model(\n",
    "    num_mixer_blocks: int,\n",
    "    patch_size: int,\n",
    "    embedding_dim: int,\n",
    "    channels_mlp_dim: int,\n",
    "    num_classes: int,\n",
    "    preprocessing_layer: Union[Sequential, None],\n",
    "    augmentation_layer: Union[Sequential, None],\n",
    ") -> Model:\n",
    "    inputs = Input(shape=(CONFIGS[\"image_size\"], CONFIGS[\"image_size\"], 3))\n",
    "    preprocessed_inputs = (\n",
    "        preprocessing_layer(inputs) if preprocessing_layer is not None else inputs\n",
    "    )\n",
    "    augmented_inputs = (\n",
    "        augmentation_layer(preprocessed_inputs)\n",
    "        if augmentation_layer is not None\n",
    "        else preprocessed_inputs\n",
    "    )\n",
    "    x = patch_embedding(augmented_inputs, embedding_dim, patch_size)\n",
    "    tokens_mlp_dim = x.shape[-2]\n",
    "    for _ in range(num_mixer_blocks):\n",
    "        x = mixer_block(x, tokens_mlp_dim, channels_mlp_dim)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dropout(CONFIGS[\"dropout\"])(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "    return Model(inputs, outputs, name=\"mlp_mixer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(relogin=True)\n",
    "run = wandb.init(project='mlp-mixer', name=\"cifar-10\", config=CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mlp_mixer_model(\n",
    "    num_mixer_blocks=CONFIGS[\"num_mixer_layers\"],\n",
    "    patch_size=CONFIGS[\"patch_size\"],\n",
    "    embedding_dim=CONFIGS[\"embedding_dim\"],\n",
    "    channels_mlp_dim=CONFIGS[\"channels_mlp_dim\"],\n",
    "    num_classes=CONFIGS[\"num_classes\"],\n",
    "    preprocessing_layer=get_preprocessing_layer(\n",
    "        data_batch=x_train, target_size=CONFIGS[\"target_size\"]\n",
    "    ),\n",
    "    augmentation_layer=get_augmentation_layer(),\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=CONFIGS[\"learning_rate\"]),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        metrics.TopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
    "        metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_callback = WandbCallback(\n",
    "    data_type='image',\n",
    "    save_model=True,\n",
    "    validation_data=(x_test, y_test),\n",
    "    labels=CONFIGS[\"class_names\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=CONFIGS[\"batch_size\"],\n",
    "    epochs=CONFIGS[\"epochs\"],\n",
    "    validation_split=0.1,\n",
    "    callbacks=[wandb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"accuracy\")\n",
    "plot_result(\"top-3-accuracy\")\n",
    "plot_result(\"top-5-accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "MLP_Mixer_Training",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
