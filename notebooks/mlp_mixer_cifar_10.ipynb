{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIYdn1woOS1n",
    "outputId": "d6a3872e-734e-4674-b8a0-0290d85d98f5"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    losses,\n",
    "    metrics,\n",
    "    datasets,\n",
    "    mixed_precision,\n",
    "    optimizers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    \"dataset_name\": \"CIFAR-10\",\n",
    "    \"image_size\": 32,\n",
    "    \"target_size\": 72,\n",
    "    \"patch_size\": 9,\n",
    "    \"num_mixer_layers\": 4,\n",
    "    \"embedding_dim\": 128,\n",
    "    \"channels_mlp_dim\": 128,\n",
    "    \"num_classes\": 10,\n",
    "    \"dropout\": 0.25,\n",
    "    \"batch_size\": 512,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"epochs\": 50,\n",
    "    \"label_smoothing\": 0.0,\n",
    "    \"mixed_precision\": True,\n",
    "    \"class_names\": [\n",
    "        \"airplane\", \"automobile\", \"bird\", \"cat\",\n",
    "        \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA RTX A6000, compute capability 8.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 22:42:29.393952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:29.423504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:29.424735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:29.426499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "if CONFIGS[\"mixed_precision\"]:\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1lbRgIu0BbTF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 32, 32, 3)\n",
      "y_train.shape: (50000, 10)\n",
      "x_test.shape: (10000, 32, 32, 3)\n",
      "y_test.shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "def get_cifar10(num_classes: int):\n",
    "    (x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = get_cifar10(num_classes=10)\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"x_test.shape:\", x_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t6qEXvcVR7ZJ"
   },
   "outputs": [],
   "source": [
    "def get_preprocessing_layer(\n",
    "    data_batch: Union[np.ndarray, tf.Tensor], target_size: int\n",
    ") -> Sequential:\n",
    "    normalization = preprocessing.Normalization()\n",
    "    normalization.adapt(data_batch)\n",
    "    resize = preprocessing.Resizing(target_size, target_size)\n",
    "    return Sequential([normalization, resize], name=\"preprocessing\")\n",
    "\n",
    "\n",
    "def get_augmentation_layer() -> Sequential:\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            preprocessing.RandomFlip(\"horizontal\"),\n",
    "            preprocessing.RandomRotation(factor=0.02),\n",
    "            preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "        ],\n",
    "        name=\"augmentation\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_8cOi71NDCPC"
   },
   "outputs": [],
   "source": [
    "def patch_embedding(\n",
    "    inputs: tf.Tensor, embedding_dim: int, patch_size: int\n",
    ") -> tf.Tensor:\n",
    "    x = layers.Conv2D(embedding_dim, kernel_size=patch_size, strides=patch_size)(inputs)\n",
    "    return layers.Reshape((x.shape[1] * x.shape[2], x.shape[3]))(x)\n",
    "\n",
    "\n",
    "def mlp_block(inputs: tf.Tensor, mlp_dim: int) -> tf.Tensor:\n",
    "    x = layers.Dense(mlp_dim)(inputs)\n",
    "    x = layers.Activation(\"gelu\")(x)\n",
    "    return layers.Dense(x.shape[-1])(x)\n",
    "\n",
    "\n",
    "def mixer_block(inputs: tf.Tensor, tokens_mlp_dim, channels_mlp_dim) -> tf.Tensor:\n",
    "    y = layers.LayerNormalization()(inputs)\n",
    "    y = layers.Permute((2, 1))(y)\n",
    "    # Token Mixing\n",
    "    y = mlp_block(y, tokens_mlp_dim)\n",
    "    y = layers.Permute((2, 1))(y)\n",
    "    x = layers.Add()([inputs, y])\n",
    "    # Channel Mixing\n",
    "    y = layers.LayerNormalization()(x)\n",
    "    y = mlp_block(y, channels_mlp_dim)\n",
    "    return layers.Add()([x, y])\n",
    "\n",
    "\n",
    "def get_mlp_mixer_model(\n",
    "    num_mixer_blocks: int,\n",
    "    patch_size: int,\n",
    "    embedding_dim: int,\n",
    "    channels_mlp_dim: int,\n",
    "    num_classes: int,\n",
    "    preprocessing_layer: Union[Sequential, None],\n",
    "    augmentation_layer: Union[Sequential, None],\n",
    ") -> Model:\n",
    "    inputs = Input(shape=(CONFIGS[\"image_size\"], CONFIGS[\"image_size\"], 3))\n",
    "    preprocessed_inputs = (\n",
    "        preprocessing_layer(inputs) if preprocessing_layer is not None else inputs\n",
    "    )\n",
    "    augmented_inputs = (\n",
    "        augmentation_layer(preprocessed_inputs)\n",
    "        if augmentation_layer is not None\n",
    "        else preprocessed_inputs\n",
    "    )\n",
    "    x = patch_embedding(augmented_inputs, embedding_dim, patch_size)\n",
    "    tokens_mlp_dim = x.shape[-2]\n",
    "    for _ in range(num_mixer_blocks):\n",
    "        x = mixer_block(x, tokens_mlp_dim, channels_mlp_dim)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Dropout(CONFIGS[\"dropout\"])(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "    return Model(inputs, outputs, name=\"mlp_mixer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/paperspace/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgeekyrakshit\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/geekyrakshit/mlp-mixer/runs/3lflfj3s\" target=\"_blank\">cifar-10-mixed-precision</a></strong> to <a href=\"https://wandb.ai/geekyrakshit/mlp-mixer\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login(relogin=True)\n",
    "run = wandb.init(\n",
    "    project='mlp-mixer',\n",
    "    name=\"cifar-10-mixed-precision\",\n",
    "    config=CONFIGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 22:42:42.345932: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-25 22:42:42.346421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:42.347754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:42.348902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:42.897246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:42.898467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:42.899630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-25 22:42:42.900754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46707 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:00:05.0, compute capability: 8.6\n",
      "2022-01-25 22:42:43.930977: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mlp_mixer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "preprocessing (Sequential)      (None, 72, 72, 3)    7           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "augmentation (Sequential)       (None, 72, 72, 3)    0           preprocessing[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 8, 8, 128)    31232       augmentation[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 64, 128)      0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 64, 128)      256         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 128, 64)      0           layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 64)      4160        permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 64)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 64)      4160        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 64, 128)      0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 128)      0           reshape[0][0]                    \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 64, 128)      256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64, 128)      16512       layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 128)      0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64, 128)      16512       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 128)      0           add[0][0]                        \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 64, 128)      256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 128, 64)      0           layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128, 64)      4160        permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 64)      0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128, 64)      4160        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 64, 128)      0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 128)      0           add_1[0][0]                      \n",
      "                                                                 permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 64, 128)      256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64, 128)      16512       layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 128)      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64, 128)      16512       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 128)      0           add_2[0][0]                      \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_4 (LayerNor (None, 64, 128)      256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 128, 64)      0           layer_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128, 64)      4160        permute_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 64)      0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128, 64)      4160        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_5 (Permute)             (None, 64, 128)      0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 128)      0           add_3[0][0]                      \n",
      "                                                                 permute_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_5 (LayerNor (None, 64, 128)      256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64, 128)      16512       layer_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 128)      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 64, 128)      16512       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 128)      0           add_4[0][0]                      \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_6 (LayerNor (None, 64, 128)      256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_6 (Permute)             (None, 128, 64)      0           layer_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128, 64)      4160        permute_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 64)      0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128, 64)      4160        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_7 (Permute)             (None, 64, 128)      0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 128)      0           add_5[0][0]                      \n",
      "                                                                 permute_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_7 (LayerNor (None, 64, 128)      256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64, 128)      16512       layer_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 128)      0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64, 128)      16512       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 128)      0           add_6[0][0]                      \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_8 (LayerNor (None, 64, 128)      256         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 128)      0           layer_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10)           1290        global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 200,209\n",
      "Trainable params: 200,202\n",
      "Non-trainable params: 7\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_mlp_mixer_model(\n",
    "    num_mixer_blocks=CONFIGS[\"num_mixer_layers\"],\n",
    "    patch_size=CONFIGS[\"patch_size\"],\n",
    "    embedding_dim=CONFIGS[\"embedding_dim\"],\n",
    "    channels_mlp_dim=CONFIGS[\"channels_mlp_dim\"],\n",
    "    num_classes=CONFIGS[\"num_classes\"],\n",
    "    preprocessing_layer=get_preprocessing_layer(\n",
    "        data_batch=x_train, target_size=CONFIGS[\"target_size\"]\n",
    "    ),\n",
    "    augmentation_layer=get_augmentation_layer(),\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=CONFIGS[\"learning_rate\"]),\n",
    "    loss=losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        metrics.TopKCategoricalAccuracy(3, name=\"top-3-accuracy\"),\n",
    "        metrics.TopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-25 22:42:49.173335: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "2022-01-25 22:42:50.324613: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-01-25 22:42:50.324893: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-01-25 22:42:50.324912: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2022-01-25 22:42:50.325179: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-01-25 22:42:50.326021: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-01-25 22:42:51.400157: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 10s 38ms/step - loss: 1.8896 - accuracy: 0.3086 - top-3-accuracy: 0.6368 - top-5-accuracy: 0.8075 - val_loss: 1.5794 - val_accuracy: 0.4274 - val_top-3-accuracy: 0.7618 - val_top-5-accuracy: 0.8968\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 1.5179 - accuracy: 0.4502 - top-3-accuracy: 0.7830 - top-5-accuracy: 0.9071 - val_loss: 1.4014 - val_accuracy: 0.4864 - val_top-3-accuracy: 0.8150 - val_top-5-accuracy: 0.9286\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 3s 30ms/step - loss: 1.3774 - accuracy: 0.5031 - top-3-accuracy: 0.8198 - top-5-accuracy: 0.9299 - val_loss: 1.2937 - val_accuracy: 0.5226 - val_top-3-accuracy: 0.8388 - val_top-5-accuracy: 0.9420\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 1.3070 - accuracy: 0.5304 - top-3-accuracy: 0.8371 - top-5-accuracy: 0.9387 - val_loss: 1.2558 - val_accuracy: 0.5366 - val_top-3-accuracy: 0.8516 - val_top-5-accuracy: 0.9520\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 1.2432 - accuracy: 0.5511 - top-3-accuracy: 0.8525 - top-5-accuracy: 0.9468 - val_loss: 1.1797 - val_accuracy: 0.5674 - val_top-3-accuracy: 0.8710 - val_top-5-accuracy: 0.9568\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 1.1979 - accuracy: 0.5702 - top-3-accuracy: 0.8625 - top-5-accuracy: 0.9515 - val_loss: 1.1441 - val_accuracy: 0.5784 - val_top-3-accuracy: 0.8784 - val_top-5-accuracy: 0.9610\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 1.1606 - accuracy: 0.5846 - top-3-accuracy: 0.8706 - top-5-accuracy: 0.9546 - val_loss: 1.1188 - val_accuracy: 0.5916 - val_top-3-accuracy: 0.8840 - val_top-5-accuracy: 0.9614\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 1.1122 - accuracy: 0.6039 - top-3-accuracy: 0.8804 - top-5-accuracy: 0.9590 - val_loss: 1.0539 - val_accuracy: 0.6154 - val_top-3-accuracy: 0.8938 - val_top-5-accuracy: 0.9652\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 1.0860 - accuracy: 0.6146 - top-3-accuracy: 0.8834 - top-5-accuracy: 0.9611 - val_loss: 1.0516 - val_accuracy: 0.6212 - val_top-3-accuracy: 0.8950 - val_top-5-accuracy: 0.9672\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 1.0588 - accuracy: 0.6222 - top-3-accuracy: 0.8901 - top-5-accuracy: 0.9636 - val_loss: 1.0049 - val_accuracy: 0.6410 - val_top-3-accuracy: 0.9024 - val_top-5-accuracy: 0.9692\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 1.0316 - accuracy: 0.6339 - top-3-accuracy: 0.8956 - top-5-accuracy: 0.9654 - val_loss: 1.0019 - val_accuracy: 0.6440 - val_top-3-accuracy: 0.8998 - val_top-5-accuracy: 0.9676\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 1.0066 - accuracy: 0.6440 - top-3-accuracy: 0.8995 - top-5-accuracy: 0.9666 - val_loss: 0.9971 - val_accuracy: 0.6436 - val_top-3-accuracy: 0.9062 - val_top-5-accuracy: 0.9702\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.9795 - accuracy: 0.6522 - top-3-accuracy: 0.9048 - top-5-accuracy: 0.9698 - val_loss: 0.9599 - val_accuracy: 0.6632 - val_top-3-accuracy: 0.9092 - val_top-5-accuracy: 0.9718\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.9547 - accuracy: 0.6630 - top-3-accuracy: 0.9091 - top-5-accuracy: 0.9714 - val_loss: 0.9683 - val_accuracy: 0.6590 - val_top-3-accuracy: 0.9084 - val_top-5-accuracy: 0.9706\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.9367 - accuracy: 0.6694 - top-3-accuracy: 0.9102 - top-5-accuracy: 0.9727 - val_loss: 0.9373 - val_accuracy: 0.6704 - val_top-3-accuracy: 0.9106 - val_top-5-accuracy: 0.9704\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.9140 - accuracy: 0.6756 - top-3-accuracy: 0.9144 - top-5-accuracy: 0.9744 - val_loss: 0.9324 - val_accuracy: 0.6674 - val_top-3-accuracy: 0.9124 - val_top-5-accuracy: 0.9734\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.9029 - accuracy: 0.6794 - top-3-accuracy: 0.9173 - top-5-accuracy: 0.9742 - val_loss: 0.9202 - val_accuracy: 0.6778 - val_top-3-accuracy: 0.9098 - val_top-5-accuracy: 0.9700\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.8841 - accuracy: 0.6871 - top-3-accuracy: 0.9199 - top-5-accuracy: 0.9763 - val_loss: 0.9018 - val_accuracy: 0.6738 - val_top-3-accuracy: 0.9182 - val_top-5-accuracy: 0.9742\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.8686 - accuracy: 0.6949 - top-3-accuracy: 0.9201 - top-5-accuracy: 0.9763 - val_loss: 0.8936 - val_accuracy: 0.6790 - val_top-3-accuracy: 0.9194 - val_top-5-accuracy: 0.9750\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.8550 - accuracy: 0.6961 - top-3-accuracy: 0.9247 - top-5-accuracy: 0.9779 - val_loss: 0.9034 - val_accuracy: 0.6780 - val_top-3-accuracy: 0.9176 - val_top-5-accuracy: 0.9754\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.8292 - accuracy: 0.7065 - top-3-accuracy: 0.9284 - top-5-accuracy: 0.9794 - val_loss: 0.8925 - val_accuracy: 0.6800 - val_top-3-accuracy: 0.9222 - val_top-5-accuracy: 0.9760\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.8251 - accuracy: 0.7082 - top-3-accuracy: 0.9295 - top-5-accuracy: 0.9794 - val_loss: 0.9031 - val_accuracy: 0.6848 - val_top-3-accuracy: 0.9166 - val_top-5-accuracy: 0.9722\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.8128 - accuracy: 0.7132 - top-3-accuracy: 0.9307 - top-5-accuracy: 0.9808 - val_loss: 0.8685 - val_accuracy: 0.6938 - val_top-3-accuracy: 0.9250 - val_top-5-accuracy: 0.9764\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.7919 - accuracy: 0.7202 - top-3-accuracy: 0.9348 - top-5-accuracy: 0.9818 - val_loss: 0.8647 - val_accuracy: 0.6952 - val_top-3-accuracy: 0.9212 - val_top-5-accuracy: 0.9756\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.7733 - accuracy: 0.7262 - top-3-accuracy: 0.9366 - top-5-accuracy: 0.9820 - val_loss: 0.8681 - val_accuracy: 0.6990 - val_top-3-accuracy: 0.9272 - val_top-5-accuracy: 0.9768\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.7686 - accuracy: 0.7265 - top-3-accuracy: 0.9379 - top-5-accuracy: 0.9822 - val_loss: 0.8388 - val_accuracy: 0.7070 - val_top-3-accuracy: 0.9288 - val_top-5-accuracy: 0.9780\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.7484 - accuracy: 0.7340 - top-3-accuracy: 0.9395 - top-5-accuracy: 0.9839 - val_loss: 0.8554 - val_accuracy: 0.7038 - val_top-3-accuracy: 0.9266 - val_top-5-accuracy: 0.9770\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.7432 - accuracy: 0.7359 - top-3-accuracy: 0.9414 - top-5-accuracy: 0.9848 - val_loss: 0.8447 - val_accuracy: 0.6962 - val_top-3-accuracy: 0.9264 - val_top-5-accuracy: 0.9798\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.7243 - accuracy: 0.7434 - top-3-accuracy: 0.9441 - top-5-accuracy: 0.9858 - val_loss: 0.8487 - val_accuracy: 0.7046 - val_top-3-accuracy: 0.9264 - val_top-5-accuracy: 0.9774\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.7129 - accuracy: 0.7491 - top-3-accuracy: 0.9441 - top-5-accuracy: 0.9849 - val_loss: 0.8429 - val_accuracy: 0.7104 - val_top-3-accuracy: 0.9260 - val_top-5-accuracy: 0.9792\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.7098 - accuracy: 0.7495 - top-3-accuracy: 0.9458 - top-5-accuracy: 0.9850 - val_loss: 0.8259 - val_accuracy: 0.7140 - val_top-3-accuracy: 0.9314 - val_top-5-accuracy: 0.9798\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.6979 - accuracy: 0.7532 - top-3-accuracy: 0.9466 - top-5-accuracy: 0.9860 - val_loss: 0.8045 - val_accuracy: 0.7170 - val_top-3-accuracy: 0.9344 - val_top-5-accuracy: 0.9826\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.6794 - accuracy: 0.7597 - top-3-accuracy: 0.9505 - top-5-accuracy: 0.9870 - val_loss: 0.8121 - val_accuracy: 0.7182 - val_top-3-accuracy: 0.9318 - val_top-5-accuracy: 0.9786\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.6745 - accuracy: 0.7622 - top-3-accuracy: 0.9505 - top-5-accuracy: 0.9871 - val_loss: 0.8085 - val_accuracy: 0.7170 - val_top-3-accuracy: 0.9300 - val_top-5-accuracy: 0.9798\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.6626 - accuracy: 0.7635 - top-3-accuracy: 0.9526 - top-5-accuracy: 0.9880 - val_loss: 0.8471 - val_accuracy: 0.7182 - val_top-3-accuracy: 0.9258 - val_top-5-accuracy: 0.9764\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.6517 - accuracy: 0.7681 - top-3-accuracy: 0.9545 - top-5-accuracy: 0.9884 - val_loss: 0.8176 - val_accuracy: 0.7266 - val_top-3-accuracy: 0.9270 - val_top-5-accuracy: 0.9782\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.6514 - accuracy: 0.7693 - top-3-accuracy: 0.9540 - top-5-accuracy: 0.9882 - val_loss: 0.8079 - val_accuracy: 0.7258 - val_top-3-accuracy: 0.9366 - val_top-5-accuracy: 0.9812\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.6337 - accuracy: 0.7737 - top-3-accuracy: 0.9553 - top-5-accuracy: 0.9894 - val_loss: 0.7997 - val_accuracy: 0.7290 - val_top-3-accuracy: 0.9332 - val_top-5-accuracy: 0.9784\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.6298 - accuracy: 0.7751 - top-3-accuracy: 0.9574 - top-5-accuracy: 0.9893 - val_loss: 0.7925 - val_accuracy: 0.7268 - val_top-3-accuracy: 0.9370 - val_top-5-accuracy: 0.9816\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.6187 - accuracy: 0.7807 - top-3-accuracy: 0.9578 - top-5-accuracy: 0.9895 - val_loss: 0.7917 - val_accuracy: 0.7280 - val_top-3-accuracy: 0.9336 - val_top-5-accuracy: 0.9804\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.6149 - accuracy: 0.7832 - top-3-accuracy: 0.9576 - top-5-accuracy: 0.9893 - val_loss: 0.8088 - val_accuracy: 0.7228 - val_top-3-accuracy: 0.9336 - val_top-5-accuracy: 0.9800\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.6046 - accuracy: 0.7842 - top-3-accuracy: 0.9597 - top-5-accuracy: 0.9907 - val_loss: 0.7878 - val_accuracy: 0.7328 - val_top-3-accuracy: 0.9334 - val_top-5-accuracy: 0.9822\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.5975 - accuracy: 0.7887 - top-3-accuracy: 0.9599 - top-5-accuracy: 0.9902 - val_loss: 0.7960 - val_accuracy: 0.7294 - val_top-3-accuracy: 0.9370 - val_top-5-accuracy: 0.9800\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.5856 - accuracy: 0.7899 - top-3-accuracy: 0.9628 - top-5-accuracy: 0.9910 - val_loss: 0.8016 - val_accuracy: 0.7288 - val_top-3-accuracy: 0.9364 - val_top-5-accuracy: 0.9810\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.5818 - accuracy: 0.7922 - top-3-accuracy: 0.9607 - top-5-accuracy: 0.9911 - val_loss: 0.8035 - val_accuracy: 0.7284 - val_top-3-accuracy: 0.9344 - val_top-5-accuracy: 0.9788\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.5785 - accuracy: 0.7941 - top-3-accuracy: 0.9627 - top-5-accuracy: 0.9919 - val_loss: 0.8120 - val_accuracy: 0.7232 - val_top-3-accuracy: 0.9360 - val_top-5-accuracy: 0.9808\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.5640 - accuracy: 0.7994 - top-3-accuracy: 0.9637 - top-5-accuracy: 0.9918 - val_loss: 0.7928 - val_accuracy: 0.7328 - val_top-3-accuracy: 0.9382 - val_top-5-accuracy: 0.9804\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 3s 31ms/step - loss: 0.5611 - accuracy: 0.8014 - top-3-accuracy: 0.9652 - top-5-accuracy: 0.9922 - val_loss: 0.7922 - val_accuracy: 0.7338 - val_top-3-accuracy: 0.9348 - val_top-5-accuracy: 0.9814\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.5504 - accuracy: 0.8026 - top-3-accuracy: 0.9663 - top-5-accuracy: 0.9928 - val_loss: 0.8027 - val_accuracy: 0.7354 - val_top-3-accuracy: 0.9362 - val_top-5-accuracy: 0.9800\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 3s 32ms/step - loss: 0.5436 - accuracy: 0.8046 - top-3-accuracy: 0.9670 - top-5-accuracy: 0.9930 - val_loss: 0.7923 - val_accuracy: 0.7334 - val_top-3-accuracy: 0.9402 - val_top-5-accuracy: 0.9818\n"
     ]
    }
   ],
   "source": [
    "wandb_callback = WandbCallback(\n",
    "    data_type='image',\n",
    "    save_model=True,\n",
    "    training_data=(x_train, y_train),\n",
    "    validation_data=(x_test, y_test),\n",
    "    labels=CONFIGS[\"class_names\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=CONFIGS[\"batch_size\"],\n",
    "    epochs=CONFIGS[\"epochs\"],\n",
    "    validation_split=0.1,\n",
    "    callbacks=[wandb_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.8261 - accuracy: 0.7225 - top-3-accuracy: 0.9301 - top-5-accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23661... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Test Top 3 Accuracy</td><td>▁</td></tr><tr><td>Test Top 5 Accuracy</td><td>▁</td></tr><tr><td>accuracy</td><td>▁▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>top-3-accuracy</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>top-5-accuracy</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr><tr><td>val_accuracy</td><td>▁▂▃▃▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>val_loss</td><td>█▆▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_top-3-accuracy</td><td>▁▃▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████▇███████████</td></tr><tr><td>val_top-5-accuracy</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>27.75</td></tr><tr><td>Test Top 3 Accuracy</td><td>6.99</td></tr><tr><td>Test Top 5 Accuracy</td><td>1.98</td></tr><tr><td>accuracy</td><td>0.8046</td></tr><tr><td>best_epoch</td><td>41</td></tr><tr><td>best_val_loss</td><td>0.78783</td></tr><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.54359</td></tr><tr><td>top-3-accuracy</td><td>0.967</td></tr><tr><td>top-5-accuracy</td><td>0.99298</td></tr><tr><td>val_accuracy</td><td>0.7334</td></tr><tr><td>val_loss</td><td>0.79231</td></tr><tr><td>val_top-3-accuracy</td><td>0.9402</td></tr><tr><td>val_top-5-accuracy</td><td>0.9818</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 1801 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">cifar-10-mixed-precision</strong>: <a href=\"https://wandb.ai/geekyrakshit/mlp-mixer/runs/3lflfj3s\" target=\"_blank\">https://wandb.ai/geekyrakshit/mlp-mixer/runs/3lflfj3s</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220125_224239-3lflfj3s/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss, accuracy, top_3_accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "wandb.log({'Test Accuracy': round((1 - accuracy) * 100, 2)})\n",
    "wandb.log({'Test Top 3 Accuracy': round((1 - top_3_accuracy) * 100, 2)})\n",
    "wandb.log({'Test Top 5 Accuracy': round((1 - top_5_accuracy) * 100, 2)})\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "MLP_Mixer_Training",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
